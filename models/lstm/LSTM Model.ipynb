{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to article explainig code:\n",
    "<url>https://cnvrg.io/pytorch-lstm/</url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed data\n",
    "df = pd.read_csv('../../dataframes/monthly_processed.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fishoil_price_peru</th>\n",
       "      <th>fish_price_global</th>\n",
       "      <th>rapeseedoil_price_global</th>\n",
       "      <th>fishmeal_price_peru</th>\n",
       "      <th>peanutoil_price_global</th>\n",
       "      <th>soybeanoil_price_global</th>\n",
       "      <th>sunfloweroil_price_global</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>-0.240038</td>\n",
       "      <td>-0.128972</td>\n",
       "      <td>0.061253</td>\n",
       "      <td>-0.078029</td>\n",
       "      <td>0.052452</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>0.060447</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>-0.063662</td>\n",
       "      <td>-0.005232</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>-0.225434</td>\n",
       "      <td>0.110635</td>\n",
       "      <td>-0.070698</td>\n",
       "      <td>-0.004688</td>\n",
       "      <td>-0.014199</td>\n",
       "      <td>-0.006982</td>\n",
       "      <td>-0.006243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>-0.108276</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>-0.027548</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.015769</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.021414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.038771</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.014319</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>-0.031662</td>\n",
       "      <td>-0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>-0.050196</td>\n",
       "      <td>0.060328</td>\n",
       "      <td>-0.015622</td>\n",
       "      <td>-0.025545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.023347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>0.139669</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.052665</td>\n",
       "      <td>-0.032722</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.049195</td>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>-0.280083</td>\n",
       "      <td>-0.078629</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.033304</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.026697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>0.260230</td>\n",
       "      <td>-0.078097</td>\n",
       "      <td>-0.010105</td>\n",
       "      <td>-0.025991</td>\n",
       "      <td>-0.022669</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>-0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>-0.451975</td>\n",
       "      <td>-0.072998</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>0.039273</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.020878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fishoil_price_peru  fish_price_global  rapeseedoil_price_global  \\\n",
       "date                                                                          \n",
       "2017-12-01           -0.240038          -0.128972                  0.061253   \n",
       "2017-11-01            0.060447          -0.012739                  0.065451   \n",
       "2017-10-01           -0.225434           0.110635                 -0.070698   \n",
       "2017-09-01           -0.108276           0.008571                 -0.027548   \n",
       "2017-08-01            0.038771           0.059369                  0.002849   \n",
       "...                        ...                ...                       ...   \n",
       "2010-05-01           -0.050196           0.060328                 -0.015622   \n",
       "2010-04-01            0.139669           0.025001                  0.052665   \n",
       "2010-03-01           -0.280083          -0.078629                  0.001044   \n",
       "2010-02-01            0.260230          -0.078097                 -0.010105   \n",
       "2010-01-01           -0.451975          -0.072998                  0.014501   \n",
       "\n",
       "            fishmeal_price_peru  peanutoil_price_global  \\\n",
       "date                                                      \n",
       "2017-12-01            -0.078029                0.052452   \n",
       "2017-11-01            -0.063662               -0.005232   \n",
       "2017-10-01            -0.004688               -0.014199   \n",
       "2017-09-01             0.019360                0.015769   \n",
       "2017-08-01            -0.014319                0.003662   \n",
       "...                         ...                     ...   \n",
       "2010-05-01            -0.025545                0.000000   \n",
       "2010-04-01            -0.032722               -0.003848   \n",
       "2010-03-01            -0.010348               -0.033304   \n",
       "2010-02-01            -0.025991               -0.022669   \n",
       "2010-01-01             0.039273               -0.009341   \n",
       "\n",
       "            soybeanoil_price_global  sunfloweroil_price_global  \n",
       "date                                                            \n",
       "2017-12-01                -0.003810                   0.002150  \n",
       "2017-11-01                 0.022328                   0.011300  \n",
       "2017-10-01                -0.006982                  -0.006243  \n",
       "2017-09-01                 0.009989                   0.021414  \n",
       "2017-08-01                -0.031662                  -0.007937  \n",
       "...                             ...                        ...  \n",
       "2010-05-01                -0.000919                   0.023347  \n",
       "2010-04-01                 0.049195                   0.015267  \n",
       "2010-03-01                 0.009085                   0.026697  \n",
       "2010-02-01                -0.002066                  -0.001054  \n",
       "2010-01-01                 0.012417                   0.020878  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use columns (x - y) as data\n",
    "#df.drop(df.columns[np.r_[x, y:len(df.columns)]], axis=1, inplace=True)\n",
    "\n",
    "# drop first x rows which contain metadata\n",
    "#df.drop(df.index[0:x], axis=0, inplace=True)\n",
    "X = df\n",
    "X.loc[(X.index >= \"2010-01-01\") & (X.index < \"2018-01-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate predictors from output\n",
    "X = df\n",
    "y = df.iloc[:, 0:1]\n",
    "y.head()\n",
    "\n",
    "# split data into train and test test\n",
    "X_train = X.loc[X.index < \"2010-01-01\"]\n",
    "X_test = X.loc[X.index >= \"2010-01-01\"]\n",
    "y_train = y.loc[X.index < \"2010-01-01\"]\n",
    "y_test = y.loc[X.index >= \"2010-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13541267, -0.01960847,  0.02613003, ..., -0.07626385,\n",
       "         0.02081281,  0.01842427],\n",
       "       [-0.24287086, -0.00795233, -0.00482891, ..., -0.02590223,\n",
       "        -0.00804367, -0.06819632],\n",
       "       [ 0.12772069, -0.04073883, -0.04340135, ...,  0.00326822,\n",
       "        -0.03868459, -0.08494068],\n",
       "       ...,\n",
       "       [-0.0494833 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.50422805,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.3678824 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (300, 7) (300, 1)\n",
      "Testing Shape (150, 7) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert data to pytorch variables\n",
    "X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test.values))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test.values)) \n",
    "\n",
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([300, 1, 7]) torch.Size([300, 1])\n",
      "Testing Shape torch.Size([150, 1, 7]) torch.Size([150, 1])\n"
     ]
    }
   ],
   "source": [
    "# reshape tensors to include timestamp\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes      # number of classes\n",
    "        self.num_layers = num_layers        # number of layers\n",
    "        self.input_size = input_size        # input size\n",
    "        self.hidden_size = hidden_size      # hidden state\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True) # lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128)        # fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes)           # fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # internal state\n",
    "        # propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) # reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) # first Dense\n",
    "        out = self.relu(out) # relu\n",
    "        out = self.fc(out) # final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable definitions\n",
    "num_epochs = 100            # 100 epochs\n",
    "learning_rate = 0.001       # 0.001 lr\n",
    "\n",
    "seq_length = 1              # sequence length\n",
    "\n",
    "input_size = 7              # number of features\n",
    "hidden_size = 2             # number of features in hidden state\n",
    "num_layers = 1              # number of stacked lstm layers\n",
    "\n",
    "num_classes = 1             # number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train and test data to sequence of length seq_length\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lstm layer \n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, seq_length) # lstm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and weight updating method\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.15744\n",
      "Epoch: 10, loss: 0.05188\n",
      "Epoch: 20, loss: 0.04882\n",
      "Epoch: 30, loss: 0.04698\n",
      "Epoch: 40, loss: 0.04449\n",
      "Epoch: 50, loss: 0.04459\n",
      "Epoch: 60, loss: 0.04398\n",
      "Epoch: 70, loss: 0.04377\n",
      "Epoch: 80, loss: 0.04343\n",
      "Epoch: 90, loss: 0.04309\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "  outputs = lstm.forward(X_train_tensors_final) # forward pass\n",
    "  optimizer.zero_grad() # calculate the gradient, manually setting to 0\n",
    " \n",
    "  # obtain the loss function\n",
    "  loss = criterion(outputs, y_train_tensors)\n",
    " \n",
    "  loss.backward() # calculates the loss of the loss function\n",
    " \n",
    "  optimizer.step() # improve from loss, i.e backprop\n",
    "  if epoch % 10 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the test set\n",
    "\n",
    "# compute loss on test set\n",
    "\n",
    "# plot test set predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fc28af60476edc3e27144daec4d860a5bfd0f3e7bdb17e7edfc0e13d60e755d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
