{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to article containing original code: <url>https://cnvrg.io/pytorch-lstm/</url><br>\n",
    "Most of the code is different due to mistakes present in original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import trange\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable that determines whether results should be saved\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read monthly processed data\n",
    "df = pd.read_csv('../../dataframes/monthly_processed.csv', index_col='date', parse_dates=True)\n",
    "df_prices = df['fishoil_price_peru_value']\n",
    "df = df.drop('fishoil_price_peru_value', axis=1)\n",
    "\n",
    "# # read weekly processed data with juveniles\n",
    "# df = pd.read_csv('../../dataframes/weekly_processed.csv', index_col='date', parse_dates=True)\n",
    "# df_prices = df['fishoil_price_peru_value']\n",
    "# df = df.drop('fishoil_price_peru_value', axis=1)\n",
    "\n",
    "# # read weekly processed data with juveniles\n",
    "# df = pd.read_csv('../../dataframes/weekly_processed_with_juveniles.csv', index_col='date', parse_dates=True)\n",
    "# df_prices = df['fishoil_price_peru_value']\n",
    "# df = df.drop('fishoil_price_peru_value', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter some of the features of the data\n",
    "# df = df[['fishoil_price_peru', 'fish_price_global', 'rapeseedoil_price_global', 'fishmeal_price_peru', 'temperature_peru', 'precipitation_peru', 'fish_production_peru', 'fishoil_export_peru']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fishoil_price_peru</th>\n",
       "      <th>fish_price_global</th>\n",
       "      <th>rapeseedoil_price_global</th>\n",
       "      <th>fishmeal_price_peru</th>\n",
       "      <th>peanutoil_price_global</th>\n",
       "      <th>soybeanoil_price_global</th>\n",
       "      <th>sunfloweroil_price_global</th>\n",
       "      <th>temperature_peru</th>\n",
       "      <th>precipitation_peru</th>\n",
       "      <th>fish_production_peru</th>\n",
       "      <th>fish_human_consumption_peru</th>\n",
       "      <th>fish_industrial_consumption_peru</th>\n",
       "      <th>gdp</th>\n",
       "      <th>fishmeal_price_hamburg</th>\n",
       "      <th>fishoil_export_peru</th>\n",
       "      <th>fishoil_fob_peru</th>\n",
       "      <th>fishoil_utilization_indicators</th>\n",
       "      <th>fishing_hours_peru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103397</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.113792</td>\n",
       "      <td>0.098321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021282</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.090283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.039221</td>\n",
       "      <td>0.197565</td>\n",
       "      <td>-3.712563</td>\n",
       "      <td>-1.172411</td>\n",
       "      <td>-0.012958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.693340</td>\n",
       "      <td>0.028711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>-0.081597</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.036826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020203</td>\n",
       "      <td>-0.071978</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>-0.026608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325054</td>\n",
       "      <td>0.131319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.214876</td>\n",
       "      <td>-0.046882</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>-0.204014</td>\n",
       "      <td>-0.454262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020619</td>\n",
       "      <td>-0.062978</td>\n",
       "      <td>0.114717</td>\n",
       "      <td>0.213405</td>\n",
       "      <td>-0.020735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.016566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05-01</th>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>0.527306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.396245</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-04-01</th>\n",
       "      <td>-0.343536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.686582</td>\n",
       "      <td>1.338285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-03-01</th>\n",
       "      <td>-0.049483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062869</td>\n",
       "      <td>0.229165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.234435</td>\n",
       "      <td>-0.282232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-02-01</th>\n",
       "      <td>0.504228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022361</td>\n",
       "      <td>0.295648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.756528</td>\n",
       "      <td>-0.252091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-01</th>\n",
       "      <td>-0.367882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>-0.797084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376235</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fishoil_price_peru  fish_price_global  rapeseedoil_price_global  \\\n",
       "date                                                                          \n",
       "2022-06-01            0.000000                0.0                  0.000000   \n",
       "2022-05-01            0.000000                0.0                  0.103397   \n",
       "2022-04-01            0.000000                0.0                  0.021282   \n",
       "2022-03-01            0.000000                0.0                 -0.046919   \n",
       "2022-02-01            0.000000                0.0                 -0.214876   \n",
       "...                        ...                ...                       ...   \n",
       "1985-05-01            0.001269                0.0                  0.000000   \n",
       "1985-04-01           -0.343536                0.0                  0.000000   \n",
       "1985-03-01           -0.049483                0.0                  0.000000   \n",
       "1985-02-01            0.504228                0.0                  0.000000   \n",
       "1985-01-01           -0.367882                0.0                  0.000000   \n",
       "\n",
       "            fishmeal_price_peru  peanutoil_price_global  \\\n",
       "date                                                      \n",
       "2022-06-01             0.000000                0.000000   \n",
       "2022-05-01             0.016131                0.000047   \n",
       "2022-04-01             0.005602               -0.000485   \n",
       "2022-03-01            -0.081597                0.003676   \n",
       "2022-02-01            -0.046882                0.138541   \n",
       "...                         ...                     ...   \n",
       "1985-05-01             0.000000                0.000000   \n",
       "1985-04-01             0.000000                0.000000   \n",
       "1985-03-01             0.000000                0.000000   \n",
       "1985-02-01             0.000000                0.000000   \n",
       "1985-01-01             0.000000                0.000000   \n",
       "\n",
       "            soybeanoil_price_global  sunfloweroil_price_global  \\\n",
       "date                                                             \n",
       "2022-06-01                 0.000000                   0.000000   \n",
       "2022-05-01                 0.113792                   0.098321   \n",
       "2022-04-01                -0.007861                   0.090283   \n",
       "2022-03-01                 0.004800                   0.036826   \n",
       "2022-02-01                -0.204014                  -0.454262   \n",
       "...                             ...                        ...   \n",
       "1985-05-01                 0.000000                   0.000000   \n",
       "1985-04-01                 0.000000                   0.000000   \n",
       "1985-03-01                 0.000000                   0.000000   \n",
       "1985-02-01                 0.000000                   0.000000   \n",
       "1985-01-01                 0.000000                   0.000000   \n",
       "\n",
       "            temperature_peru  precipitation_peru  fish_production_peru  \\\n",
       "date                                                                     \n",
       "2022-06-01          0.000000            0.000000              0.000000   \n",
       "2022-05-01          0.000000            0.000000              0.000000   \n",
       "2022-04-01          0.000000            0.000000             -0.039221   \n",
       "2022-03-01          0.000000            0.000000             -0.020203   \n",
       "2022-02-01          0.000000            0.000000             -0.020619   \n",
       "...                      ...                 ...                   ...   \n",
       "1985-05-01          0.051774            0.527306              0.000000   \n",
       "1985-04-01          0.025439           -0.039544              0.000000   \n",
       "1985-03-01          0.062869            0.229165              0.000000   \n",
       "1985-02-01         -0.022361            0.295648              0.000000   \n",
       "1985-01-01          0.003511           -0.797084              0.000000   \n",
       "\n",
       "            fish_human_consumption_peru  fish_industrial_consumption_peru  \\\n",
       "date                                                                        \n",
       "2022-06-01                     0.000000                          0.000000   \n",
       "2022-05-01                     0.000000                          0.000000   \n",
       "2022-04-01                     0.197565                         -3.712563   \n",
       "2022-03-01                    -0.071978                          0.349140   \n",
       "2022-02-01                    -0.062978                          0.114717   \n",
       "...                                 ...                               ...   \n",
       "1985-05-01                     0.000000                          0.000000   \n",
       "1985-04-01                     0.000000                          0.000000   \n",
       "1985-03-01                     0.000000                          0.000000   \n",
       "1985-02-01                     0.000000                          0.000000   \n",
       "1985-01-01                     0.000000                          0.000000   \n",
       "\n",
       "                 gdp  fishmeal_price_hamburg  fishoil_export_peru  \\\n",
       "date                                                                \n",
       "2022-06-01  0.000000                0.000000             0.000000   \n",
       "2022-05-01  0.000000                0.012453             0.000000   \n",
       "2022-04-01 -1.172411               -0.012958             0.000000   \n",
       "2022-03-01  0.035878               -0.026608             0.000000   \n",
       "2022-02-01  0.213405               -0.020735             0.000000   \n",
       "...              ...                     ...                  ...   \n",
       "1985-05-01  0.000000                0.000000             1.396245   \n",
       "1985-04-01  0.000000                0.000000             1.686582   \n",
       "1985-03-01  0.000000                0.000000            -0.234435   \n",
       "1985-02-01  0.000000                0.000000            -0.756528   \n",
       "1985-01-01  0.000000                0.000000             0.376235   \n",
       "\n",
       "            fishoil_fob_peru  fishoil_utilization_indicators  \\\n",
       "date                                                           \n",
       "2022-06-01          0.000000                        0.000000   \n",
       "2022-05-01          0.000000                        0.000000   \n",
       "2022-04-01          0.000000                       -3.693340   \n",
       "2022-03-01          0.000000                        0.325054   \n",
       "2022-02-01          0.000000                        0.095745   \n",
       "...                      ...                             ...   \n",
       "1985-05-01          1.386294                        0.000000   \n",
       "1985-04-01          1.338285                        0.000000   \n",
       "1985-03-01         -0.282232                        0.000000   \n",
       "1985-02-01         -0.252091                        0.000000   \n",
       "1985-01-01          0.006969                        0.000000   \n",
       "\n",
       "            fishing_hours_peru  \n",
       "date                            \n",
       "2022-06-01            0.000000  \n",
       "2022-05-01            0.000000  \n",
       "2022-04-01            0.028711  \n",
       "2022-03-01            0.131319  \n",
       "2022-02-01            0.016566  \n",
       "...                        ...  \n",
       "1985-05-01            0.000000  \n",
       "1985-04-01            0.000000  \n",
       "1985-03-01            0.000000  \n",
       "1985-02-01            0.000000  \n",
       "1985-01-01            0.000000  \n",
       "\n",
       "[450 rows x 18 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for how many years we have all the features in total\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable definitions\n",
    "num_epochs = 50                 # number of epochs\n",
    "learning_rate = 0.001           # 0.001 lr\n",
    "\n",
    "seq_length = 36                 # sequence length of sequence given to the LSTM layer\n",
    "pred_length = 12                # prediction length of output sequence produced by LSTM layer \n",
    "                                # (multiples of twelve since there is yearly seasonality)\n",
    "                                \n",
    "input_size = len(df.columns)    # number of features (amount of input variables)\n",
    "output_size = 1                 # size of output (peru fish oil price so just one variable)\n",
    "hidden_size = 32                # number of features in hidden state (this number should be treated as a hyperparameter)\n",
    "num_layers = 2                  # number of stacked lstm layers\n",
    "dropout = 0                     # probability for dropout cells\n",
    "\n",
    "num_classes = pred_length       # number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create list of sequences of length seq_length\n",
    "def create_series(data, data_prices, first_price, target):\n",
    "    # the amount of time-steps for which we have data\n",
    "    total_timesteps = len(data)\n",
    "\n",
    "    # arrays that hold the input sequences and the corresponding target sequences respectively.\n",
    "    sequencesX, sequencesY, sequencesZ, prices = [], [], [], []\n",
    "    if (total_timesteps < seq_length + pred_length):\n",
    "        # verify that enough time-steps of the data are available to create input sequence with their corresponding targets.\n",
    "        raise Exception(\"This dataframe cannot be used to create sequences of length \" + str(seq_length + pred_length))\n",
    "    \n",
    "    # find the index of the target feature\n",
    "    index = data.columns.get_loc(target)\n",
    "\n",
    "    # create all possible sequences of length seq_length and their \n",
    "    for i in range(total_timesteps - seq_length - pred_length):\n",
    "        # append the input sequence\n",
    "        sequencesX.append(data.iloc[i:(i+seq_length), :])\n",
    "\n",
    "        # append the corresponding (target) output sequence\n",
    "        target_processed = data.iloc[(i+seq_length):(i+seq_length+pred_length), index:(index+1)].values\n",
    "        \n",
    "        # collect data and convert back to price data\n",
    "        target_prices = []\n",
    "        for value in target_processed:\n",
    "            if len(target_prices) == 0:\n",
    "                if i == 0:\n",
    "                    target_prices.append((np.e ** value) * first_price)\n",
    "                else:\n",
    "                    target_prices.append((np.e ** value) * data_prices[i-1])\n",
    "            else:\n",
    "                target_prices.append((np.e ** value) * target_prices[-1])\n",
    "        target_prices\n",
    "\n",
    "        # append the output prices\n",
    "        prices.append(target_prices)\n",
    "\n",
    "        lowest_price_index = np.array(target_prices).argmin()\n",
    "        vector = np.zeros(pred_length)\n",
    "        vector[lowest_price_index] = 1\n",
    "\n",
    "        # append binary vector of month containing lowest price\n",
    "        sequencesY.append(vector)\n",
    "\n",
    "        # append price of last element of input sequence\n",
    "        sequencesZ.append(data_prices.iloc[i+seq_length-1])\n",
    "    \n",
    "    # return the sequences\n",
    "    return np.array(sequencesX), np.array(sequencesY), np.array(sequencesZ), np.array(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block the X and y sets are created.\n",
    "\n",
    "The shape of `X` is as follows:<br>\n",
    "The element `X[s][i][j]` contains the value of the $j$'th input variable (out of the `len(df.columns)` different input variables) at the $i$'th time-step (out of the `seq_length` time-steps in the sequence) for the $s$'th sequence in the data set `X`.<br>\n",
    "\n",
    "The shape of `y` is as follows:<br>\n",
    "The element `y[s][i][0]` contains the value of the peru fish oil price (target) at the $i$'th time-step (out of the `pred_length` time-steps in the sequence) for the $s$'th sequence in the data set `y`.<br>\n",
    "The last zero-index is used because all the values are wrapped in length one arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output shapes respectively: (188, 36, 18) (188, 12)\n",
      "Testing input/output shapes respectively: (13, 36, 18) (13, 12)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "training_set_p = 0.8\n",
    "\n",
    "df_cut_off = df[df.index > \"1996-12-01\"]\n",
    "df_prices_cut_off = df_prices[df_prices.index > \"1996-12-01\"]\n",
    "split_id = int(len(df_cut_off)*training_set_p)\n",
    "# TODO: May also need a validation set to determine optimal hyperparameters\n",
    "# df_train = df[(df.index > \"1996-12-01\") & (df.index < \"2010-01-01\")]    # use only past 1997 due to geopolitical changes\n",
    "# df_test = df[df.index >= \"2010-01-01\"]\n",
    "df_train = df_cut_off[:split_id]\n",
    "df_train = df_train[df_train.index < \"2021-12-01\"]\n",
    "df_train = df_train.drop(df_train.tail(1).index) # drop last row\n",
    "\n",
    "df_train_prices = df_prices_cut_off[:split_id]\n",
    "df_train_first_price = df_train_prices.tail(1)\n",
    "df_train_prices = df_train_prices.drop(df_train_prices.tail(1).index) # drop last row\n",
    "\n",
    "df_test = df_cut_off[split_id:]\n",
    "df_test = df_test.drop(df_test.tail(1).index) # drop last row\n",
    "\n",
    "df_test_prices = df_prices_cut_off[split_id:]\n",
    "df_test_first_price = df_test_prices.tail(1)\n",
    "df_test_prices = df_test_prices.drop(df_test_prices.tail(1).index) # drop last row\n",
    "\n",
    "\n",
    "'''\n",
    "Use validation set\n",
    "training_set_p = 0.6\n",
    "valid_set_p = 0.2\n",
    "\n",
    "df_cut_off = df[df.index > \"1996-12-01\"]\n",
    "train_split_id = int(len(df_cut_off)*training_set_p)\n",
    "val_set_id = int(len(df_cut_off)*valid_set_p)\n",
    "# TODO: May also need a validation set to determine optimal hyperparameters\n",
    "# df_train = df[(df.index > \"1996-12-01\") & (df.index < \"2010-01-01\")]    # use only past 1997 due to geopolitical changes\n",
    "# df_test = df[df.index >= \"2010-01-01\"]\n",
    "df_train = df_cut_off[:train_split_id]\n",
    "df_val = df_cut_off[train_split_id:train_split_id+val_set_id]\n",
    "df_test = df_cut_off[train_split_id+val_set_id:]\n",
    "'''\n",
    "\n",
    "# create the sequences to train on\n",
    "X_train, y_train, y_train_prices, y_train_price_values  = create_series(df_train, df_train_prices, df_train_first_price, 'fishoil_price_peru')\n",
    "\n",
    "# create the sequences to test on\n",
    "X_test, y_test, y_test_prices, y_test_price_values = create_series(df_test, df_test_prices, df_test_first_price, 'fishoil_price_peru')\n",
    "\n",
    "# target index\n",
    "target_index = df.columns.get_loc('fishoil_price_peru')\n",
    "\n",
    "# print shapes\n",
    "print(\"Training input/output shapes respectively:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing input/output shapes respectively:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are converted to PyTorch tensors and the shapes are printed.<br>\n",
    "The input shape is of the form `(nr_of_sequences, seq_length, input_size)`.<br>\n",
    "The output shape is of the form `(nr_of_sequences, pred_length, output_size)`.\n",
    "\n",
    "If this needs to be reshaped the `torch.reshape(data, shape)` function can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output shapes respectively: torch.Size([188, 36, 18]) torch.Size([188, 36, 18])\n",
      "Testing input/output shapes respectively: torch.Size([13, 36, 18]) torch.Size([13, 12])\n"
     ]
    }
   ],
   "source": [
    "# convert data to pytorch variables\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test)) \n",
    "\n",
    "# flatten the output tensors to remove unnecassary dimension\n",
    "y_train_tensors = torch.flatten(y_train_tensors, 1)\n",
    "y_test_tensors = torch.flatten(y_test_tensors, 1)\n",
    "\n",
    "# print shapes\n",
    "print(\"Training input/output shapes respectively:\", X_train_tensors.shape, X_train_tensors.shape)\n",
    "print(\"Testing input/output shapes respectively:\", X_test_tensors.shape, y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input size of the first fully connected layer is equal to `(hidden_size * seq_length)` because the LSTM outputs the hidden state (containing `hidden_size` variables) for every time-step in the input which contains `seq_length` time-steps. The output size of this layer is a hyperparameter for which a default of twice the amount of inputs is used.\n",
    "\n",
    "The lstm layer can also use an initial hidden state and initial cell state for each time-step in the sequence of `seq_length` but since these are not provided it defaults to zero.<br>\n",
    "See the input section of the <a url=https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>documentation</a> for more information.\n",
    "\n",
    "The output of the lstm layer is `output, (output_hidden_states, output_cell_states)` where `output` contains for every sequence in the provided `input` the hidden state at each time-step.<br>\n",
    "Furthermore, `output_hidden_states` and `output_cell_states` contain for every sequence the hidden state and cell state of the last time-step, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes      # number of classes\n",
    "        self.num_layers = num_layers        # number of layers\n",
    "        self.input_size = input_size        # input size\n",
    "        self.hidden_size = hidden_size      # hidden state\n",
    "\n",
    "        fc_1_input_size = hidden_size * seq_length\n",
    "        fc_1_output_size = hidden_size * seq_length * 2     # output size of first fully connected layer (hyperparameter)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True) # lstm\n",
    "        self.fc_1 = nn.Linear(fc_1_input_size, fc_1_output_size) # first fully connected layer\n",
    "        self.fc_2 = nn.Linear(fc_1_output_size, num_classes) # second fully connected layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # propagate input through LSTM\n",
    "        output, (output_hidden_states, output_cell_states) = self.lstm(input) # retrieve output from lstm by providing input (the initial hidden and cell states can be set but default sets to zero)\n",
    "        flattened_output = torch.flatten(output) # flattened output\n",
    "        out = self.relu(flattened_output) # relu\n",
    "        out = self.fc_1(out) # first fully connected layer\n",
    "        out = self.relu(out) # relu\n",
    "        out = self.fc_2(out) # second fully connected layer\n",
    "        out = self.softmax(out) # softmax \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lstm layer\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, dropout) # lstm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and weight updating method\n",
    "criterion = torch.nn.CrossEntropyLoss()   # cross-entropy loss for classification\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<01:25,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.59100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:16<00:55,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.61838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:30<00:40,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:44<00:27,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:58<00:12,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:11<00:00,  1.44s/it]\n",
      "  2%|▏         | 1/50 [00:02<02:21,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.47496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:30<01:44,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.60805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:57<01:16,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:23<00:50,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:50<00:24,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.68s/it]\n",
      "  2%|▏         | 1/50 [00:01<01:31,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.60711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:20<01:12,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.69204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:39<00:54,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 1.62013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:59<00:36,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 1.62555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:18<00:17,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 1.62857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:36<00:00,  1.93s/it]\n",
      "  2%|▏         | 1/50 [00:03<02:56,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.60795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:39<02:24,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:15<01:43,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:50<01:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:27<00:32,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:00<00:00,  3.60s/it]\n",
      "  2%|▏         | 1/50 [00:02<01:43,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.58743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:22<01:21,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:44<01:01,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:05<00:40,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:27<00:19,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:46<00:00,  2.14s/it]\n",
      "  2%|▏         | 1/50 [00:03<03:01,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.61329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:40<02:24,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:18<01:48,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:55<01:10,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:32<00:33,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:06<00:00,  3.73s/it]\n",
      "  2%|▏         | 1/50 [00:02<02:24,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.55265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:33<02:02,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.63215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:09<01:46,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 1.61879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:47<01:10,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 1.61879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:24<00:33,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 1.61875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:57<00:00,  3.56s/it]\n",
      "  2%|▏         | 1/50 [00:05<04:18,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.61398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:03<03:54,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:02<02:49,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [03:00<01:50,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [03:59<00:52,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, loss: 2.61873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:52<00:00,  5.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "def train_model(hidden_size, num_layers, dropout):\n",
    "  best_loss = np.inf\n",
    "  # create the lstm layer\n",
    "  lstm = LSTM(num_classes, input_size, hidden_size, num_layers, dropout) # lstm layer\n",
    "  criterion = torch.nn.CrossEntropyLoss()    # cross-entropy loss for classification\n",
    "  optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "  losses = []\n",
    "  avg_losses = []\n",
    "  for epoch in trange(num_epochs):\n",
    "    # using batches of size 1\n",
    "    losses_during_epoch = []\n",
    "    for sequence in range(X_train_tensors.size(0)):\n",
    "      output = lstm.forward(X_train_tensors[sequence].unsqueeze(dim=0)) # forward pass\n",
    "      optimizer.zero_grad() # calculate the gradient, manually setting to 0\n",
    "      # obtain the loss function\n",
    "      loss = criterion(output, y_train_tensors[sequence])\n",
    "      loss.backward() # calculates the loss of the loss function\n",
    "      optimizer.step() # improve from loss, i.e backprop\n",
    "      losses_during_epoch.append(loss.item())\n",
    "    avg_losses.append(np.mean(losses_during_epoch))\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # if average loss over the epoch is the lowest so far, update the model\n",
    "    if np.mean(losses_during_epoch) < best_loss:\n",
    "      best_loss = np.mean(losses_during_epoch)\n",
    "      best_model = lstm\n",
    "    if epoch % 10 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "\n",
    "  if save:\n",
    "    save_location = \"../trained_models_seq_length={}/lstm_h={}_layers={}_dropout={}\".format(seq_length, hidden_size, num_layers, str(dropout == 0.5))\n",
    "  else:\n",
    "    save_location = \"../trained_models_temp/lstm_h={}_layers={}_dropout={}\".format(hidden_size, num_layers, str(dropout == 0.5))\n",
    "  \n",
    "  torch.save(best_model.state_dict(), save_location)\n",
    "  \n",
    "  return best_model, losses, avg_losses\n",
    "\n",
    "def calculate_mse(lstm):\n",
    "  '''Calculates the  MSE over the whole test set'''\n",
    "  # make predictions for the test set using lstm and baseline models and compute the losses\n",
    "  lstm_outputs = []\n",
    "  lstm_losses = []\n",
    "\n",
    "  # first sequence in test set are not used to ease baseline computation\n",
    "  for sequence in range(X_test_tensors.size(0)):\n",
    "      # output of lstm layer\n",
    "      lstm_output = lstm.forward(X_test_tensors[sequence].unsqueeze(dim=0))\n",
    "\n",
    "      # compute losses\n",
    "      loss_lstm = criterion(lstm_output, y_test_tensors[sequence])\n",
    "\n",
    "      # save the outputs\n",
    "      lstm_outputs.append(lstm_output.detach().numpy())\n",
    "\n",
    "      # save the losses\n",
    "      lstm_losses.append(loss_lstm.detach().numpy())\n",
    "  return np.mean(lstm_losses)\n",
    "\n",
    "def grid_search(hidden_size_list, num_layers_list, dropout_list):\n",
    "  '''Performs a grid search to find optimal hyperparameters'''\n",
    "  data_log = []\n",
    "  for hidden_size in hidden_size_list:\n",
    "    for num_layers in num_layers_list:\n",
    "      for dropout in dropout_list:\n",
    "        lstm, losses, avg_losses = train_model(hidden_size, num_layers, dropout)\n",
    "        avg_mse = calculate_mse(lstm)\n",
    "        data_log.append({'hidden dimensions': int(hidden_size), \n",
    "                          'lstm layers': int(num_layers), \n",
    "                          'dropout': float(dropout), \n",
    "                          'loss_list': losses, \n",
    "                          'avg_losses': avg_losses, \n",
    "                          'avg mse': float(avg_mse)})\n",
    "  json_string = json.dumps(data_log)\n",
    "  if save:\n",
    "    f = open('grid_search_results_{}.json'.format(seq_length), 'w')\n",
    "  else:\n",
    "    f = open('grid_search_results_temp.json', 'w')\n",
    "  f.write(json_string)\n",
    "  f.close()\n",
    "\n",
    "grid_search([2, 4, 8, 16], [1, 2], [0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The past baseline predicts that the next 12 months of fish oil log ratios will be exactly those observed last year.<br>\n",
    "The repeat baselines predicts that the next 12 months of fish oil log ratios will all be equal to the last observed fish oil log ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results of the grid search\n",
    "if save:\n",
    "    results = pd.read_json('grid_search_results_{}.json'.format(seq_length))\n",
    "else:\n",
    "    results = pd.read_json('grid_search_results_temp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden dimensions</th>\n",
       "      <th>lstm layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>avg mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.234114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.234114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.234114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.234115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.234236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.266543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.306132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.452207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden dimensions  lstm layers  dropout   avg mse\n",
       "7                 16            2        0  2.234114\n",
       "4                  8            1        0  2.234114\n",
       "5                  8            2        0  2.234114\n",
       "3                  4            2        0  2.234115\n",
       "1                  2            2        0  2.234236\n",
       "0                  2            1        0  2.266543\n",
       "6                 16            1        0  2.306132\n",
       "2                  4            1        0  2.452207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = results.sort_values('avg mse')\n",
    "display(results[['hidden dimensions', 'lstm layers', 'dropout', 'avg mse']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(18, 16, num_layers=2, batch_first=True)\n",
       "  (fc_1): Linear(in_features=576, out_features=1152, bias=True)\n",
       "  (fc_2): Linear(in_features=1152, out_features=12, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params = results.iloc[0]\n",
    "lstm = LSTM(num_classes, input_size, optimal_params['hidden dimensions'], optimal_params['lstm layers'], 0)\n",
    "if save:\n",
    "    lstm.load_state_dict(torch.load(\"../trained_models_seq_length={}/lstm_h={}_layers={}_dropout={}\".format(seq_length, optimal_params['hidden dimensions'],\n",
    "                                                                            optimal_params['lstm layers'],\n",
    "                                                                            str(optimal_params['dropout'] == 0.5))))\n",
    "else:\n",
    "    lstm.load_state_dict(torch.load(\"../trained_models_temp/lstm_h={}_layers={}_dropout={}\".format(optimal_params['hidden dimensions'],\n",
    "                                                                            optimal_params['lstm layers'],\n",
    "                                                                            str(optimal_params['dropout'] == 0.5))))\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM(num_classes, input_size, 16, 2, 0)\n",
    "lstm.load_state_dict(torch.load(\"../trained_models_seq_length=36/lstm_h=16_layers=2_dropout=False\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the test set using lstm and baseline models and compute the losses\n",
    "lstm_outputs = []\n",
    "baseline_past_outputs = []\n",
    "lstm_losses = []\n",
    "baseline_past_losses = []\n",
    "\n",
    "for sequence in range(X_test_tensors.size(0)):\n",
    "    # output of lstm layer\n",
    "    lstm_output = lstm.forward(X_test_tensors[sequence].unsqueeze(dim=0))\n",
    "\n",
    "    # output of baseline using past data\n",
    "    baseline_past_output = X_test_tensors[sequence][seq_length-pred_length:seq_length][:,0]\n",
    "\n",
    "    # compute losses\n",
    "    loss_lstm = criterion(lstm_output, y_test_tensors[sequence])\n",
    "    loss_baseline_past = criterion(baseline_past_output, y_test_tensors[sequence])\n",
    "\n",
    "    # save the outputs\n",
    "    lstm_outputs.append(lstm_output.detach().numpy())\n",
    "    baseline_past_outputs.append(baseline_past_output.numpy())\n",
    "\n",
    "    # save the losses\n",
    "    lstm_losses.append(loss_lstm.detach().numpy())\n",
    "    baseline_past_losses.append(loss_baseline_past.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(sequence):   \n",
    "    # collect data and format\n",
    "    data = {'Target': y_test_price_values[sequence].flatten(), 'LSTM': lstm_outputs[sequence], 'Baseline': baseline_past_outputs[sequence]}\n",
    "    df_performance = pd.DataFrame(data)\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM loss</th>\n",
       "      <th>Baseline loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.5982254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.63137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.3939636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.6343944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.632524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.6521409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6187294</td>\n",
       "      <td>2.5578575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.603014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.6187294</td>\n",
       "      <td>2.9593909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.6187294</td>\n",
       "      <td>2.4143143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.6187294</td>\n",
       "      <td>2.5733654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.6187294</td>\n",
       "      <td>2.65894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.6187294</td>\n",
       "      <td>2.6391392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSTM loss Baseline loss\n",
       "0   2.6187294     2.5982254\n",
       "1   2.6187294       2.63137\n",
       "2   2.6187294     2.3939636\n",
       "3   2.6187294     2.6343944\n",
       "4   2.6187294      2.632524\n",
       "5   2.6187294     2.6521409\n",
       "6   1.6187294     2.5578575\n",
       "7   2.6187294      2.603014\n",
       "8   1.6187294     2.9593909\n",
       "9   1.6187294     2.4143143\n",
       "10  1.6187294     2.5733654\n",
       "11  1.6187294       2.65894\n",
       "12  2.6187294     2.6391392"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_losses = pd.DataFrame({'LSTM loss': lstm_losses, 'Baseline loss': baseline_past_losses})\n",
    "df_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475.778845</td>\n",
       "      <td>8.317305e-25</td>\n",
       "      <td>0.129236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467.680869</td>\n",
       "      <td>1.970201e-29</td>\n",
       "      <td>-0.315812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469.773605</td>\n",
       "      <td>1.465352e-30</td>\n",
       "      <td>0.097856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>729.545761</td>\n",
       "      <td>2.816961e-32</td>\n",
       "      <td>-0.047030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499.344866</td>\n",
       "      <td>6.684135e-33</td>\n",
       "      <td>0.047476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594.882787</td>\n",
       "      <td>3.680314e-29</td>\n",
       "      <td>0.068071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>604.891521</td>\n",
       "      <td>4.757482e-31</td>\n",
       "      <td>0.007882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>554.665871</td>\n",
       "      <td>9.194816e-29</td>\n",
       "      <td>0.141557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>448.664274</td>\n",
       "      <td>1.150230e-28</td>\n",
       "      <td>0.063574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>691.876523</td>\n",
       "      <td>1.342423e-29</td>\n",
       "      <td>0.408490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>445.752642</td>\n",
       "      <td>1.649633e-31</td>\n",
       "      <td>-0.082264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>592.699063</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.131160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target          LSTM  Baseline\n",
       "0   475.778845  8.317305e-25  0.129236\n",
       "1   467.680869  1.970201e-29 -0.315812\n",
       "2   469.773605  1.465352e-30  0.097856\n",
       "3   729.545761  2.816961e-32 -0.047030\n",
       "4   499.344866  6.684135e-33  0.047476\n",
       "5   594.882787  3.680314e-29  0.068071\n",
       "6   604.891521  4.757482e-31  0.007882\n",
       "7   554.665871  9.194816e-29  0.141557\n",
       "8   448.664274  1.150230e-28  0.063574\n",
       "9   691.876523  1.342423e-29  0.408490\n",
       "10  445.752642  1.649633e-31 -0.082264\n",
       "11  592.699063  1.000000e+00  0.131160"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prices(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean minimum price of the target over the test set: 334.4669673496013\n",
      "Mean average price of the target over the test set: 444.82701372391756\n",
      "Mean maximum price of the target over the test set: 605.2267598025769\n",
      "Mean price lstm: 468.6970866193594\n",
      "Mean price baseline: 372.7673851488307\n",
      "LSTM beat baseline  1  times out of  13\n"
     ]
    }
   ],
   "source": [
    "# create arrays to remember each years predicted lowest price\n",
    "prices_min = []\n",
    "prices_lstm = []\n",
    "prices_baseline = []\n",
    "prices_average = []\n",
    "prices_max= []\n",
    "count_lstm = 0\n",
    "\n",
    "for sequence in range(X_test_tensors.size(0)):\n",
    "    prices = get_prices(sequence)\n",
    "\n",
    "    # append lowest price of target\n",
    "    prices_min.append(prices['Target'].min())\n",
    "    \n",
    "    # append average price of target\n",
    "    prices_average.append(np.mean(prices['Target']))\n",
    "    \n",
    "    # append maximum price of target\n",
    "    prices_max.append(prices['Target'].max())\n",
    "\n",
    "    # append actual price of predicted lowest price of lstm\n",
    "    prices_lstm.append(prices.sort_values('LSTM').reset_index()['Target'][0])\n",
    "\n",
    "    # append actual price of predicted lowest price of baseline\n",
    "    prices_baseline.append(prices.sort_values('Baseline').reset_index()['Target'][0])\n",
    "\n",
    "    # count how often the lstm outperformed the baseline\n",
    "    if prices_lstm[-1] <= prices_baseline[-1]:\n",
    "        count_lstm += 1\n",
    "\n",
    "# TODO: Figure out how well this compares to the actions of DSMs purchasing team\n",
    "print('Mean minimum price of the target over the test set:', np.mean(prices_min))\n",
    "print('Mean average price of the target over the test set:', np.mean(prices_average))\n",
    "print('Mean maximum price of the target over the test set:', np.mean(prices_max))\n",
    "print('Mean price lstm:', np.mean(prices_lstm))\n",
    "print('Mean price baseline:', np.mean(prices_baseline))\n",
    "print('LSTM beat baseline ', count_lstm, ' times out of ', X_test_tensors.size(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95cdb06e919eab5e2c554174537356ac9b55200d1eb6f880dc25de04343a18ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
